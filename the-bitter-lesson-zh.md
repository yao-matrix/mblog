# 苦涩的教训

回望人工智能 70 年的研究历程，我们学到的最深刻的教训是: 基于计算的通用方法成为了最后的赢家，远胜其它方法。其背后的根本原因是摩尔定律，或者更确切地说是由其所驱动的每单位计算成本持续的指数式降低。大多数人工智能研究都是基于“智能体的可用算力恒定”这一假设，在这种情况下，利用人类知识就几乎成为能够提高智能体表现的唯一方法。但现实情况是，仅仅经过一个比典型研究项目稍长的时间跨度，算力就会出现一个很大的跃升。为了追求短期突破，研究人员往往会将其在该领域的人类知识植入系统，但从长远来看，真正重要的是计算能力的发挥。这两者在原则上未必相互矛盾，但在实践中却往往是矛盾的。因为时间就那么多，如果在其中之一上花费很多时间，那么在另一个上花费的时间就会相应变少。此外，对其中一种方法的投资会形成沉没成本，进而造成路径依赖，使得更难切换至另一种方法。同时，人类知识的加入往往会使解决方案变得复杂，因而不能很好地利用那些能发挥算力的通用方法。对人工智能研究人员而言，迟来的教训比比皆是，回顾其中那些最突出的例子或许能给我们带来不少启发。

第一个例子来自国际象棋领域，1997 年击败世界冠军卡斯帕罗夫的深蓝使用了大规模深度搜索方法。当时，大多数计算机国际象棋研究人员对此感到沮丧，他们心仪的是那种能像人类那样深刻“理解”国际象棋规则的方法。当发现他们被基于专用硬件及软件的、更简单的、基于搜索的方法打败时，这些押注于人类知识的国际象棋研究人员心有不甘。他们表示，虽然这次“暴力”搜索可能赢了，但其绝非通用策略，毋宁说人类无论如何也不是这么下棋的。这些研究人员希望合乎人类知识的方法能够获胜，对此次失利大感失望。

仅仅 20 年后，围棋领域重演了国际象棋的故事。起初，研究人员付出了巨大的努力去利用人类知识或围棋特有的规则以避免搜索，后面的故事大家都知道了，搜索一上马，所有此类努力都被证明是徒劳的，甚至是阻碍发展的。另外一个重要的方法是利用自我对弈来学习价值函数（该方法在许多其他游戏甚至国际象棋中都有使用，虽然在 1997 年首次击败世界冠军的程序中并未发挥重要作用）。对于基于自我对弈的学习、一般意义上的学习以及搜索而言，大算力能派上很大的用场。搜索和学习是人工智能研究中能利用大量算力的最重要的两类技术。在计算机围棋中，就如同在计算机国际象棋中一样，研究人员最初的努力方向是利用人类的知识以缩小搜索空间，直到很久以后，才转而拥抱搜索和学习并大获成功。

第三个例子是语音识别。早在 20 世纪 70 年代 DARPA 就赞助了一个语音识别竞赛 TIMIT。很多参赛者使用了一系列基于人类知识的特殊方法 —— 如单词、音素、人声道等知识。另一些参赛者尝试了新的、基于隐马尔可夫模型（HMM）的统计方法，这类方法依赖更多的计算。没错，统计方法再次战胜了基于人类知识的方法。这推动了之后几十年自然语言处理领域的重大变化，在这一过程中，统计和计算逐渐在该领域占据了的主导地位。最近语音识别领域深度学习的兴起正是该方向上迈出的最新一步。深度学习方法对人类知识的依赖更少，对算力的依赖更多，并在巨大的训练集上学习，因此可以创造出更好的语音识别系统。与上面计算机下棋的例子一样，研究人员总是试图让系统按照其自以为的思维方式工作 —— 他们试图将这些知识植入系统中 —— 但事实证明，最终只能适得其反，而且，随着摩尔定律让大规模计算触手可得，且我们已经找到方法可以充分利用这些算力，这些基于人类知识的方法被证明最终只是在浪费研究人员的时间。

在计算机视觉领域，也存在类似的模式。早期的方法将视觉视为检测边缘、广义柱体或 SIFT 特征。但今天，这一切都被抛弃了。当代深度学习神经网络仅利用了卷积及某些不变性概念，且表现更佳。

这些都是前车之鉴，但整个行业尚未从中吸取足够的教训，因为我们还在继续犯同样的错误。要看清楚这些错误，并避免重蹈覆辙，我们必须充分了解这些错误的根源。我们必须吸取惨痛的教训，从长远来看，建立在我们自认的思考方式上的方法是行不通的。有史可鉴：1）人工智能研究人员常常试图将他们的知识植入到智能体中，2）这种做法在短期内一般是有效的，并且给研究人员带来成就感，但 3）从长远来看，这种做法反而造就了停滞，甚至阻碍了进一步的进展，4）突破性的进展反而是经由基于搜索和学习的可扩展的计算方法而实现的。最终的成功带有一丝苦涩，而且似乎很难接受，因为其与受我们青睐的、以人类为中心的方法相悖。

从这个惨痛的教训中，我们学到的第一点是，通用方法的强大力量，其力量会随着算力的增长而持续增强。目前来看，似乎会随着可用算力的增长而任意扩展的两种方法是搜索和学习。第二点是，心智的复杂程度是我们难以想象的。我们应该放弃对心智的简单建模，如放弃对空间、目标、多智能体以及对称性等的简化建模，它们都是复杂的外部世界的表象而已。我们不应将其作为固有元素植入系统，因为其复杂性是无限的；相反，我们应该只构建可以发现并描述这种任意复杂度的元方法。这些方法的本质特点是其可以自行找到良好的近似值，即对近似值的搜索是由方法完成的，而不是由我们自己完成的。我们希望智能体能够像我们一样进行发现，而不是仅被植入了我们已发现的东西。**将我们的发现植入系统中，只会使得理解发现本身变得更加困难。**

> 英文原文: <url> http://www.incompleteideas.net/IncIdeas/BitterLesson.html </url>
> 原文作者：Rich Sutton
> 译者: Matrix Yao (姚伟峰)
